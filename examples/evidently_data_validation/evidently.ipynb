{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Data Validation With Evidently\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Data profiling and validation is the process of examining and analyzing data to understand its characteristics, patterns, and quality. The goal of this process is to gain insight into the data, identify potential issues or errors, and ensure that the data is fit for its intended use.\n",
    "\n",
    "Evidently is a Python package that provides tools for data profiling and validation. Evidently makes it easy to generate reports on your data, which can provide insights into its distribution, missing values, correlation, and other characteristics. These reports can be visualized and examined to better understand the data and identify any potential issues or errors.\n",
    "\n",
    "Data validation involves testing the quality and consistency of the data. This can be done using a variety of techniques, such as checking for missing values, duplicate records, and outliers, as well as testing the consistency and accuracy of the data. Evidently provides a suite of tests that can be used to evaluate the quality of the data, and provides scores and metrics for each test, as well as an overall data quality score.\n",
    "\n",
    "ZenML implements some standard steps that you can use to get reports or test your\n",
    "data with Evidently for quality and other purposes. These steps are:\n",
    "\n",
    "* `EvidentlyReportStep` and `EvidentlySingleDatasetReportStep`: These steps generate\n",
    "a report for one or two given datasets. Similar to how you configure an Evidently\n",
    "Report, you can configure a list of metrics, metric presets or metrics generators\n",
    "for the step as parameters. The full list of metrics can be found\n",
    "[here](https://docs.evidentlyai.com/reference/all-metrics/).\n",
    "\n",
    "* `EvidentlyTestStep` and `EvidentlySingleDatasetTestStep`: These step test one\n",
    "or two given datasets using various Evidently tests. Similar to how you configure\n",
    "an Evidently TestSuite, you can configure a list of tests, a test presets or\n",
    "test generators for the step as parameters. The full list of tests can be found\n",
    "[here](https://docs.evidentlyai.com/reference/all-tests/).\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run\n",
    "it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/evidently_drift_detection/evidently.ipynb)\n",
    "or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/evidently_drift_detection) directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool, Evidently and scikit-learn\n",
    "\n",
    "!pip install zenml \n",
    "!zenml integration install evidently sklearn -y\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create a ZenML repository for this project by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1"
   },
   "outputs": [],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to have an Evidently Data Validator component to your stack to be able to use Evidently data profiling in your ZenML pipelines. Creating such a stack is easily accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!zenml data-validator register evidently -f evidently\n",
    "!zenml stack register evidently_stack -o default -a default -dv evidently --set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvFo9epOUE7G",
    "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rich import print\n",
    "from sklearn import datasets\n",
    "\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps, with the exception of the Evidently data drift built-in step that is shipped with ZenML."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is a `data_loader` step that downloads the OpenML women's e-commerce clothing reviews dataset and returns it as a panda DataFrame. We'll use this as the reference dataset for our data drift detection example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VT_PAW10jbp",
    "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def data_loader() -> pd.DataFrame:\n",
    "    \"\"\"Load the OpenML women's e-commerce clothing reviews dataset.\"\"\"\n",
    "    reviews_data = datasets.fetch_openml(\n",
    "        name=\"Womens-E-Commerce-Clothing-Reviews\", version=2, as_frame=\"auto\"\n",
    "    )\n",
    "    reviews = reviews_data.frame\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `data_splitter` step that takes the input dataset and splits it into two subsets. Later on, in the pipeline, we'll compare these datasets against each other using Evidently and generate a data drift profile and associated dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEw7Cbqx0wXj",
    "outputId": "0603fa51-eb20-4c22-d499-9e7f1f3a972b"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def data_splitter(\n",
    "    reviews: pd.DataFrame,\n",
    ") -> Output(reference_dataset=pd.DataFrame, comparison_dataset=pd.DataFrame):\n",
    "    \"\"\"Splits the dataset into two subsets, the reference dataset and the\n",
    "    comparison dataset.\n",
    "    \"\"\"\n",
    "    ref_df = reviews[reviews.Rating > 3].sample(\n",
    "        n=5000, replace=True, ignore_index=True, random_state=42\n",
    "    )\n",
    "    comp_df = reviews[reviews.Rating < 3].sample(\n",
    "        n=5000, replace=True, ignore_index=True, random_state=42\n",
    "    )\n",
    "    return ref_df, comp_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Next, we add an Evidently step that takes in the reference dataset and partial dataset and generates a data profile report. This step is already defined as part of the ZenML library, so we only need to add it to our pipeline with a custom configuration. Under the hood, ZenML uses Evidently in the implementation of this step to generate Evidently reports and Materializers to automatically persist them as Artifacts into the Artifact Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.metrics import EvidentlyMetricConfig\n",
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyColumnMapping,\n",
    "    EvidentlyReportParameters,\n",
    "    evidently_report_step,\n",
    ")\n",
    "\n",
    "text_data_report = evidently_report_step(\n",
    "    step_name=\"text_data_report\",\n",
    "    params=EvidentlyReportParameters(\n",
    "        column_mapping=EvidentlyColumnMapping(\n",
    "            target=\"Rating\",\n",
    "            numerical_features=[\"Age\", \"Positive_Feedback_Count\"],\n",
    "            categorical_features=[\n",
    "                \"Division_Name\",\n",
    "                \"Department_Name\",\n",
    "                \"Class_Name\",\n",
    "            ],\n",
    "            text_features=[\"Review_Text\", \"Title\"],\n",
    "        ),\n",
    "        metrics=[\n",
    "            EvidentlyMetricConfig.metric(\"DataQualityPreset\"),\n",
    "            EvidentlyMetricConfig.metric(\n",
    "                \"TextOverviewPreset\", column_name=\"Review_Text\"\n",
    "            ),\n",
    "            EvidentlyMetricConfig.metric_generator(\n",
    "                \"ColumnRegExpMetric\",\n",
    "                columns=[\"Review_Text\", \"Title\"],\n",
    "                reg_exp=r\"[A-Z][A-Za-z0-9 ]*\",\n",
    "            ),\n",
    "        ],\n",
    "        # We need to download the NLTK data for the TextOverviewPreset\n",
    "        download_nltk_data=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "This next step serves as an example showing how the Evidently profile returned as output from the previous step can be used in other steps in the pipeline to analyze the data drift report in detail and take different actions depending on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "@step\n",
    "def text_analyzer(\n",
    "    report: str,\n",
    ") -> Output(ref_missing_values=int, comp_missing_values=int):\n",
    "    \"\"\"Analyze the Evidently text Report and return the number of missing\n",
    "    values in the reference and comparison datasets.\n",
    "    \"\"\"\n",
    "    result = json.loads(report)[\"metrics\"][0][\"result\"]\n",
    "    return (\n",
    "        result[\"current\"][\"number_of_missing_values\"],\n",
    "        result[\"reference\"][\"number_of_missing_values\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run.\n",
    "\n",
    "Note how the ZenML Evidently step returns two artifacts: the Evidently Report in both JSON and HTML formats. We only use the JSON report in the pipeline, while the HTML report will be extracted and rendered separately in the post execution workflow, via the ZenML Evidently visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def text_data_report_test_pipeline(\n",
    "    data_loader,\n",
    "    data_splitter,\n",
    "    text_report,\n",
    "    text_analyzer,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline.\"\"\"\n",
    "    data = data_loader()\n",
    "    reference_dataset, comparison_dataset = data_splitter(data)\n",
    "    report, _ = text_report(\n",
    "        reference_dataset=reference_dataset,\n",
    "        comparison_dataset=comparison_dataset,\n",
    "    )\n",
    "    text_analyzer(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6"
   },
   "outputs": [],
   "source": [
    "pipeline_instance = text_data_report_test_pipeline(\n",
    "    data_loader=data_loader(),\n",
    "    data_splitter=data_splitter(),\n",
    "    text_report=text_data_report,\n",
    "    text_analyzer=text_analyzer(),\n",
    ")\n",
    "pipeline_instance.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post execution workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did mention above that the Materializer takes care of persisting the Evidently HTML reports in the Artifact Store. These artifacts can be extracted and visualized after the pipeline run is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "\n",
    "last_run = pipeline_instance.get_runs()[0]\n",
    "text_analysis_step = last_run.get_step(step=\"text_analyzer\")\n",
    "\n",
    "print(\n",
    "    \"Reference missing values: \",\n",
    "    text_analysis_step.outputs[\"ref_missing_values\"].read(),\n",
    ")\n",
    "print(\n",
    "    \"Comparison missing values: \",\n",
    "    text_analysis_step.outputs[\"comp_missing_values\"].read(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ZenML Evidently visualizer takes in a ZenML pipeline step run and renders the Evidently report that was generated during its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_report_step = last_run.get_step(step=\"text_report\")\n",
    "\n",
    "EvidentlyVisualizer().visualize(text_report_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "You have successfully used ZenML and Evidently to generate and visualize data reports.\n",
    "\n",
    "For more ZenML features and use-cases, you should check out some of the other ZenML examples. You should also take a look at our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) repo, or even better, join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "zenenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d0be979a033ea269fe1e2ffc63671e75ef3a9ac1410289007bbd9ed1b686109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
